{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========= Preparing Model =========#\n",
    "if opt.embs_share_weight:\n",
    "    assert training_data.dataset.src_word2idx == training_data.dataset.tgt_word2idx, \\\n",
    "        'The src/tgt word2idx table are different but asked to share word embedding.'\n",
    "\n",
    "print(opt)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "n_src_vocab = 148669 ##QNLI\n",
    "n_src_vocab = 143179 ##MNLI\n",
    "\n",
    "# n_src_vocab = 30522 ## BERT TOKEN \n",
    "n_src_vocab = 800 ## ATIS TOKEN \n",
    "# n_src_vocab = 6329 ## EN TOKEN \n",
    "\n",
    "n_trg_vocab = 10839\n",
    "d_word_vec = 768\n",
    "n_layers = 2\n",
    "n_head = 12\n",
    "d_q = d_word_vec//n_head\n",
    "d_k = d_word_vec//n_head\n",
    "d_v = d_word_vec//n_head\n",
    "d_model = 768\n",
    "d_inner = 3072\n",
    "pad_idx = None\n",
    "dropout = 0.1\n",
    "n_position = 512\n",
    "scale_emb = True\n",
    "\n",
    "# emb_shape = [[15,20,20,25],[4,4,8,6]]\n",
    "# emb_shape = [[16,20,10,10],[4,4,8,6]]\n",
    "# emb_shape = [[5,5,4,8],[4,4,8,6]]\n",
    "# emb_shape = [[5,5,4,4,2],[3,4,4,4,4]] #ATIS shape\n",
    "emb_shape = [[8,5,5,4,8],[4,4,4,4,3]]\n",
    "# emb_shape = [[10,10,10,10],[4,4,8,6]]\n",
    "\n",
    "\n",
    "emb_rank = 30\n",
    "emb_tensor_type = 'TensorTrainMatrix'\n",
    "\n",
    "trg_shape = [[10,10,10,11],[4,4,8,6]]\n",
    "trg_emb_rank = 30\n",
    "trg_tensor_type = 'TensorTrainMatrix'\n",
    "\n",
    "r = 20\n",
    "r_attn = 20\n",
    "\n",
    "attention_shape = [[12,8,8,8,8,12],[12,8,8,8,8,12]]\n",
    "# attention_rank = [r_attn,r_attn]\n",
    "attention_rank = [[1,12,r_attn,r_attn,r_attn,12,1], [1,12,r_attn,r_attn,r_attn,12,1]]\n",
    "# attention_rank = [[1,r_attn,r_attn,r_attn,r_attn,r_attn,1], [1,r_attn,r_attn,r_attn,r_attn,r_attn,1]]\n",
    "attention_tensor_type = 'TensorTrain'\n",
    "\n",
    "ffn_shape = [[12,8,8,12,16,16],[16,16,12,8,8,12]]\n",
    "# ffn_rank = [r,r]\n",
    "ffn_rank = [[1,12,r,r,r,16,1], [1,16,r,r,r,12,1]]\n",
    "# ffn_rank = [[1,r,r,r,r,r,1], [1,r,r,r,r,r,1]]\n",
    "\n",
    "ffn_tensor_type = 'TensorTrain'\n",
    "\n",
    "# attention_shape = [[4,4,8,6,4,4,8,6],[4,4,8,6,4,4,8,6]]\n",
    "# attention_rank = [r,r]\n",
    "# attention_tensor_type = 'TensorTrain'\n",
    "\n",
    "# ffn_shape = [[4,4,8,6,6,8,8,8],[6,8,8,8,4,4,8,6]]\n",
    "# ffn_rank = [r,r]\n",
    "# ffn_tensor_type = 'TensorTrain'\n",
    "\n",
    "bit_attn = 8\n",
    "scale_attn = 2**(-5)\n",
    "bit_ffn = 8\n",
    "scale_ffn = 2**(-5)\n",
    "bit_a = 8\n",
    "scale_a = 2**(-5)\n",
    "\n",
    "# bit_attn = 32\n",
    "# scale_attn = 2**(-0)\n",
    "# bit_ffn = 32\n",
    "# scale_ffn = 2**(-0)\n",
    "# bit_a = 32\n",
    "# scale_a = 2**(-0)\n",
    "\n",
    "# bit_attn = 4\n",
    "# scale_attn = 2**(-5)\n",
    "# bit_ffn = 4\n",
    "# scale_ffn = 2**(-5)\n",
    "# bit_a = 4\n",
    "# scale_a = 2**(-5)\n",
    "\n",
    "# bit_attn = 2\n",
    "# scale_attn = 2**(-5)\n",
    "# bit_ffn = 2\n",
    "# scale_ffn = 2**(-5)\n",
    "# bit_a = 2\n",
    "# scale_a = 2**(-5)\n",
    "\n",
    "\n",
    "d_classifier=768\n",
    "num_class = 22 #ATIS\n",
    "slot_num = 121 #ATIS\n",
    "\n",
    "# num_class = 60 #en\n",
    "# slot_num = 56 #en\n",
    "dropout_classifier = 0.1\n",
    "\n",
    "# slot_num = 120\n",
    "# num_class = 21\n",
    "\n",
    "\n",
    "# classifier_shape = [4,4,8,6,4,4,8,6]\n",
    "classifier_shape = [12,8,8,8,8,12]\n",
    "classifier_rank = [1,12,r,r,r,12,1]\n",
    "# classifier_rank = [1,r,r,r,r,r,1]\n",
    "\n",
    "classifier_tensor_type = 'TensorTrain'\n",
    "\n",
    "quantized = False\n",
    "tensorized = (opt.tensorized == 1)\n",
    "precondition = False\n",
    "\n",
    "uncompressed = opt.uncompressed\n",
    "\n",
    "from tensor_layers.Transformer_tensor import Transformer_sentence_concat_SLU\n",
    "transformer = Transformer_sentence_concat_SLU(n_src_vocab, d_word_vec, n_layers, n_head, d_q, d_k, d_v,\n",
    "            d_model, d_inner, pad_idx, dropout=dropout, n_position=n_position, scale_emb=scale_emb,\n",
    "            emb_shape = emb_shape,emb_rank = emb_rank, emb_tensor_type = emb_tensor_type,\n",
    "            attention_shape = attention_shape, attention_rank = attention_rank,attention_tensor_type = attention_tensor_type,\n",
    "            ffn_shape = ffn_shape, ffn_rank = ffn_rank,ffn_tensor_type = ffn_tensor_type,\n",
    "            d_classifier=d_classifier,num_class=num_class,dropout_classifier=dropout_classifier,\n",
    "            classifier_shape = classifier_shape,classifier_rank = classifier_rank,classifier_tensor_type = classifier_tensor_type,\n",
    "            bit_attn = bit_attn, scale_attn = scale_attn, \n",
    "            bit_ffn = bit_ffn, scale_ffn = scale_ffn,\n",
    "            bit_a = bit_a, scale_a = scale_a,\n",
    "            slot_num = slot_num,\n",
    "            quantized=quantized,\n",
    "            tensorized = tensorized,\n",
    "            uncompressed=uncompressed)\n",
    "\n",
    "transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17010e9482637207e2881aa54cd78fa6a842c0515d16e99f693c5a499c225640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
