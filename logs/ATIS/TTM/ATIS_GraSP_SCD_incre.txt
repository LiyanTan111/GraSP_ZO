Namespace(batch_size=64, config='configs/ATIS/GraSP/FO.yml', d_inner_hid=2048, d_k=64, d_model=768, d_v=64, dropout=0.1, embs_share_weight=False, epoch=100, label_smoothing=True, log=None, n_head=8, n_layers=6, n_warmup_steps=40000, no_cuda=False, ops_idx=None, precondition=0, proj_share_weight=True, quantized=1, save_mode='best', save_model='model/ATIS_GraSP_SCD_incre', src_vocab_size=19213, tensorized=0, tgt_vocab_size=10839, uncompressed=0)
Transformer_sentence_concat_SLU(
  (encoder): Encoder(
    (src_word_emb): Embedding(800, 768)
    (position_enc): Embedding(512, 768)
    (token_type_emb): Embedding(2, 768)
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_stack): ModuleList(
      (0): EncoderLayer(
        (slf_attn): MultiHeadAttention(
          (w_qs): Linear(in_features=768, out_features=768, bias=True)
          (w_ks): Linear(in_features=768, out_features=768, bias=True)
          (w_vs): Linear(in_features=768, out_features=768, bias=True)
          (fc): Linear(in_features=768, out_features=768, bias=True)
          (attention): ScaledDotProductAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        )
        (pos_ffn): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=3072, bias=True)
          (w_2): Linear(in_features=3072, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (relu): GELU(approximate='none')
        )
      )
      (1): EncoderLayer(
        (slf_attn): MultiHeadAttention(
          (w_qs): Linear(in_features=768, out_features=768, bias=True)
          (w_ks): Linear(in_features=768, out_features=768, bias=True)
          (w_vs): Linear(in_features=768, out_features=768, bias=True)
          (fc): Linear(in_features=768, out_features=768, bias=True)
          (attention): ScaledDotProductAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        )
        (pos_ffn): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=3072, bias=True)
          (w_2): Linear(in_features=3072, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (relu): GELU(approximate='none')
        )
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  )
  (preclassifier): Linear(in_features=768, out_features=768, bias=True)
  (slot_preclassifier): Linear(in_features=768, out_features=768, bias=True)
  (classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): Tanh()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=768, out_features=22, bias=True)
  )
  (slot_classifier): Sequential(
    (0): Linear(in_features=768, out_features=768, bias=True)
    (1): GELU(approximate='none')
    (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (3): Linear(in_features=768, out_features=121, bias=True)
  )
)
0
=> config.summary_dir:    ./runs/pruning/ATIS/attn/ADAM/ATIS_GraSP_FO/run_None/summary/
=> config.checkpoint_dir: ./runs/pruning/ATIS/attn/ADAM/ATIS_GraSP_FO/run_None/checkpoint/
{'Total': 16479119, 'Trainable': 16479119}
=> Applying weight initialization(kaiming).
Iteration of: 0/1
(1): Iterations 0/1.
(2): Iterations 0/1.
(2): Iterations 1/1.
** norm factor: tensor(0.2894, device='cuda:0')
** accept:  tensor(-4.0298e-05, device='cuda:0')
tensor(154454, device='cuda:0')
=> Using GraSP
=> Using a preset learning rate schedule:
{0: 0.001, 20: 0.0001, 50: 1e-05}

epoch =  0
  - (Training)   loss:  0.06008, loss_hard:  0.00000, accuracy: 73.018 %, slot accuracy: 68.627,elapse: 0.043 min
  - (Validation) loss:  0.05318, accuracy: 71.400 %, slot accuracy: 75.539,elapse: 0.006 min
  - (Test) loss:  0.05599, accuracy: 70.773 %, slot accuracy: 72.086,elapse: 0.006 min

epoch =  1
  - (Training)   loss:  0.04809, loss_hard:  0.00000, accuracy: 73.911 %, slot accuracy: 78.535,elapse: 0.042 min
  - (Validation) loss:  0.04996, accuracy: 71.400 %, slot accuracy: 79.344,elapse: 0.006 min
  - (Test) loss:  0.05157, accuracy: 70.773 %, slot accuracy: 78.317,elapse: 0.006 min

epoch =  2
  - (Training)   loss:  0.04478, loss_hard:  0.00000, accuracy: 73.933 %, slot accuracy: 82.535,elapse: 0.043 min
  - (Validation) loss:  0.04598, accuracy: 72.600 %, slot accuracy: 82.711,elapse: 0.006 min
  - (Test) loss:  0.04628, accuracy: 70.773 %, slot accuracy: 81.416,elapse: 0.006 min

epoch =  3
  - (Training)   loss:  0.04089, loss_hard:  0.00000, accuracy: 75.586 %, slot accuracy: 84.258,elapse: 0.044 min
  - (Validation) loss:  0.04342, accuracy: 74.800 %, slot accuracy: 83.500,elapse: 0.007 min
  - (Test) loss:  0.04403, accuracy: 73.460 %, slot accuracy: 82.584,elapse: 0.007 min

epoch =  4
  - (Training)   loss:  0.03872, loss_hard:  0.00000, accuracy: 79.920 %, slot accuracy: 85.472,elapse: 0.045 min
  - (Validation) loss:  0.04132, accuracy: 77.200 %, slot accuracy: 84.587,elapse: 0.007 min
  - (Test) loss:  0.04204, accuracy: 75.140 %, slot accuracy: 84.035,elapse: 0.007 min

epoch =  5
  - (Training)   loss:  0.03697, loss_hard:  0.00000, accuracy: 82.488 %, slot accuracy: 86.258,elapse: 0.044 min
  - (Validation) loss:  0.03974, accuracy: 78.800 %, slot accuracy: 85.324,elapse: 0.006 min
  - (Test) loss:  0.04043, accuracy: 77.940 %, slot accuracy: 84.788,elapse: 0.006 min

epoch =  6
  - (Training)   loss:  0.03563, loss_hard:  0.00000, accuracy: 84.007 %, slot accuracy: 86.852,elapse: 0.044 min
  - (Validation) loss:  0.03888, accuracy: 79.400 %, slot accuracy: 85.376,elapse: 0.006 min
  - (Test) loss:  0.03944, accuracy: 79.171 %, slot accuracy: 85.312,elapse: 0.006 min

epoch =  7
  - (Training)   loss:  0.03466, loss_hard:  0.00000, accuracy: 85.571 %, slot accuracy: 87.256,elapse: 0.045 min
  - (Validation) loss:  0.03801, accuracy: 81.200 %, slot accuracy: 86.183,elapse: 0.006 min
  - (Test) loss:  0.03860, accuracy: 80.515 %, slot accuracy: 85.770,elapse: 0.006 min

epoch =  8
  - (Training)   loss:  0.03392, loss_hard:  0.00000, accuracy: 87.000 %, slot accuracy: 87.500,elapse: 0.046 min
  - (Validation) loss:  0.03735, accuracy: 82.400 %, slot accuracy: 85.779,elapse: 0.006 min
  - (Test) loss:  0.03804, accuracy: 81.523 %, slot accuracy: 85.552,elapse: 0.006 min

epoch =  9
  - (Training)   loss:  0.03332, loss_hard:  0.00000, accuracy: 87.938 %, slot accuracy: 87.803,elapse: 0.045 min
  - (Validation) loss:  0.03667, accuracy: 83.000 %, slot accuracy: 86.235,elapse: 0.006 min
  - (Test) loss:  0.03751, accuracy: 81.299 %, slot accuracy: 86.196,elapse: 0.006 min
