GraSP:
  exp_name: "incre_scratch_tt_scd"
  network: tt
  depth: 2
  dataset: mnist
  batch_size: 1024
  epoch: 15
  learning_rate: 0.0005
  weight_decay: 1e-4
  exception: -1
  iterations: 1
  normalize: false
  target_ratio: 0.99
  pruner: False
  pruner_file: False
  num_classes: 10
  samples_per_class: 10
  samples_batches: 5
  num_iters: 1

optimizer:
  name: ZO_SCD_mask
  grad_sparsity: 0.8
  opt_layers_strs: 'TensorizedLinear'

scheduler:
  name: 'PresetLRScheduler'
  lr_schedule: {0: 1,
                5: 0.1,
                10: 0.01}

# scheduler:
#   name: 'ExponentialLR'
#   gamma: 0.995
#   epoch_wise: False

run:
  runs: None
  n_epochs: 100
  batch_size: 32
  use_cuda: 1
  gpu_id: 0
  deterministic: 1
  log_interval: 200
  train_noise: 0

pretrained:
  incre: True
  load_model_path: 'runs/pruning/mnist/tt/ADAM/False/tt_fo_adam/20230315-001140/run_None/finetune_mnist_tt2_r0.95_it0_best.pth.tar'
  pruned: False

model:
  tensorized: 'TensorizedLinear'
  rank: 0.1
  dropouts: 0.1
